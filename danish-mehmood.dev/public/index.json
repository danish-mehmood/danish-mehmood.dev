[{"categories":["microservices"],"content":"In this blog post I discuss what service mesh is, what problem does it solve and what are best known service mesh products are","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":" Table Of Contents  Part 1 - Microservices Architecture Deep Dive  Part 2 - API Gateways and Backend For Frontend Pattern  Part 3 - Microservices Communication  Part 4 - Service Discovery  Part 5 - Service Mesh  you are here ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"The Problem Imagine you are working with a microservices architecture and you have 10s of services running, And these services work together by communicating with each other to achieve a goal. Now imagine every team working on different microservices built using different tech stack need to write the inter service communication logic by hand. Thats a waste of time and effort. Isn’t it?. Because not only you have to call the services apis but you also need to handle things like retry logic, load balancing, api sercurity,service discovery, rate limiting, authentication, observeability and much more. Writing all this logic for every service in the system is cumbersome and error prone. Because now alot of time is going in to writing the communication middleware for the service and not the actual logic of the service. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:1:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"The Solution Service meshes present a very good solution to this problem, service mesh is a peice of software that abstracts away all the communication logic from the application layer and takes it to the network, now the application doesn’t need to worry about the communication detail and only need to focus on the service logic itself. a service mesh is a dedicated infrastructure layer for facilitating service-to-service communications between services or microservices using a proxy. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:2:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"API Gateway Vs Service Mesh API gateways and service meshes are two different architectural components that address different concerns in a microservices-based application. While they may have some overlapping functionality, they serve distinct purposes and are often used together for a comprehensive solution. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:3:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"API Gateway: Edge component: An API gateway is an entry point for external clients (such as web browsers, mobile apps, or other services) to access the microservices in the application. It acts as a reverse proxy and a single point of entry for all incoming requests, abstracting the underlying microservices from the clients. Request routing: It routes requests from clients to the appropriate microservices, based on the API path and other criteria. Authentication and authorization: API gateways often handle authentication and authorization for incoming requests, ensuring that only authorized clients can access the microservices. Rate limiting and throttling: It can enforce rate limiting and throttling policies on incoming requests to protect the application from being overwhelmed by excessive traffic. API transformation and aggregation: An API gateway can modify or transform requests and responses, as well as aggregate data from multiple microservices to provide a cohesive response to the client. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:3:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Service mesh: Internal communication: A service mesh is primarily focused on managing, controlling, and observing communication between microservices within the distributed system, rather than external client requests. Sidecar proxies: A service mesh uses lightweight network proxies (sidecars) deployed alongside each microservice, which handle inter-service traffic, enabling features like load balancing, traffic routing, and security enforcement. Resilience and fault tolerance: It provides resiliency features like circuit breaking, retries, and timeouts to enhance the fault tolerance of the microservices communication. Observability: A service mesh offers built-in observability for metrics, logs, and tracing, which enables in-depth monitoring and troubleshooting of microservices interactions. Security: It can enforce security policies such as mutual TLS, ensuring secure and encrypted communication between microservices. In summary, an API gateway is focused on managing external client access to microservices, whereas a service mesh manages communication between microservices within the distributed system. Both components can complement each other, with the API gateway serving as the ingress point for external requests and the service mesh ensuring reliable and secure communication within the application. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:3:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Key Concepts: Service mesh architecture is designed to provide a dedicated infrastructure layer for managing, controlling, and observing communication between microservices in a distributed system. Key components and concepts of service mesh architecture include: Data Plane The data plane is responsible for managing the traffic between microservices. It consists of lightweight network proxies, called sidecars, that are deployed alongside each microservice instance. Sidecars intercept and manage inter-service communication, handling tasks such as load balancing, traffic routing, and enforcing security policies. Control Plane The control plane is the central management layer of the service mesh, responsible for configuring and monitoring the data plane. It provides an interface for users to define and enforce policies, configurations, and traffic rules. The control plane also collects metrics, logs, and tracing information from the sidecars to provide observability into the microservices’ communication. Sidecar Proxy A sidecar proxy is a lightweight network proxy deployed alongside each microservice instance, which intercepts and manages the traffic between microservices. Sidecar proxies are typically implemented using technologies like Envoy or Linkerd. They are responsible for load balancing, traffic routing, circuit breaking, retries, timeouts, and enforcing security policies such as mutual TLS. Traffic Management A service mesh enables fine-grained traffic management, allowing users to control and manipulate the flow of traffic between microservices. This includes features such as request routing based on criteria like headers, weights, or versions, load balancing algorithms, fault injection for testing purposes, and traffic shifting for canary deployments or blue-green rollouts. Observability A service mesh provides built-in observability for the entire microservices ecosystem. It typically includes collecting metrics for performance and resource usage, distributed tracing for end-to-end visibility of request flows, and log aggregation for troubleshooting and analysis. This information can be consumed by monitoring and visualization tools, helping users understand the behavior and health of their microservices. Security A service mesh can enhance the security of microservices communication by providing features like mutual TLS for encrypting traffic and ensuring the identity of communicating services. Additionally, it can enforce fine-grained access control policies based on various criteria such as service identity, request attributes, or metadata. Resiliency The service mesh architecture helps increase the overall resiliency of microservices-based applications by providing features like circuit breaking, retries, and timeouts, which mitigate the impact of failures, delays, and network issues. These features help improve the fault tolerance of the system and ensure the availability of critical services. In a service mesh architecture, the data plane and control plane work together to provide a comprehensive solution for managing, controlling, and observing microservices communication, allowing developers to focus on their application’s business logic while the service mesh handles the complexities of inter-service communication. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:4:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Advantages Of Service Mesh Advanced Traffic Management Enables fine-grained control over traffic routing, including canary deployments, blue-green deployments, and traffic splitting based on specific conditions. Service Discovery and Load Balancing Automatically discovers services and ensures optimal load balancing between instances. Observability Provides deep insights into system behavior through distributed tracing, metrics, and logging without modifying application code. Enhanced Security Facilitates mutual TLS (mTLS) encryption for service-to-service communication and enforces security policies at the network level. Fault Tolerance Includes built-in mechanisms such as retries, timeouts, circuit breakers, and rate limiting to improve resilience. Policy Enforcement Allows the implementation of custom policies for traffic control, authentication, authorization, and rate limiting. Decoupling Communication Logic Removes communication-related concerns (e.g., retries, encryption, and telemetry) from application code, simplifying the development process. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:5:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Disadvantages Of Service Mesh Increased Complexity Adds an additional layer to the architecture, requiring expertise to configure, deploy, and maintain effectively. Performance Overhead The sidecar proxies in a service mesh introduce latency and consume additional CPU and memory resources. Operational Overhead Requires setting up and maintaining the service mesh infrastructure, which may include upgrades, troubleshooting, and monitoring. Learning Curve Teams must invest time to understand service mesh concepts, tools, and configuration. Cost Implications More resources (compute, network, and storage) are needed to run the service mesh components, potentially increasing operational costs. Risk of Overengineering For small-scale systems or simple use cases, implementing a service mesh might be unnecessary and lead to overengineering. Compatibility Issues Integrating a service mesh with existing legacy systems or specific protocols might be challenging. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:6:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"The Patterns ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:7:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Sidecar Proxy Pattern This is the most popular and foundational pattern in service mesh architecture. A proxy (like Envoy) runs alongside each application instance in the same pod (in Kubernetes) or host. The proxy intercepts all inbound and outbound traffic, handling routing, observability, and security. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:7:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Service Mesh with eBPF This Uses EBPF (Extended Berkeley Packet Filter) in the Linux kernel to handle communication. Avoids traditional proxies by running network-related operations directly in the kernel. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:7:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Sidecar-Less Mesh Pattern Removes the need for individual sidecars by embedding proxy logic into the node or network infrastructure. The mesh logic can be integrated into the application runtime or centralized. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:7:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Examples Of Service Mesh Software Likerd Consul Istio Cilium ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:8:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Service discovery is an essential process in any distributed microservices environment, as it makes the environment scalable and solves a very specific communication problem. In this blog post I will go deep into this process and what are the different patterns used to implement this.","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":" Table Of Contents  Part 1 - Microservices Architecture Deep Dive  Part 2 - API Gateways and Backend For Frontend Pattern  Part 3 - Microservices Communication  Part 4 - Service Discovery  you are here  Part 5 - Service Mesh ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"The Problem As i discussed in the last blog post, the communication patterns in microservices are way different than the patterns in monoliths, in monoliths the modules communicate using method calls but in case of microservices, services communicate using the network calls. This small difference has massive implications, now the services which are involved in communication are living potentially on different machines and to communicate over the network the services would need to know each others IP addresses. The naive solution is to hard code the IP addresses of every service the communicating service needs to communicate with in the code, but this is not prudent in case of highly distributed environments like microservices. But why? the reason is this that modern microservices are deployed in containers and they are also auto scaled, scaled up and down, both ways. As a result all these microservice instances running are highly ephemeral and tools like kubernetes are used to make sure all the services are up all the time. And the way it makes sure that the services are up and running is by running new instances of the service when it notices some instance go down or being problematic. Due to all this the IP addresses of the services are no more static and they keep on changing. And our solution of hard coding the servies IP addresses is rendered obsolete. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:1:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"The Solution: Service Registry The solution is service registry, we would have an additional service running at all times, which would act as a registry for all the services in the environment. Every new service which would be available in the environment would register to the service registry. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"The Process The service registry is running on the known IP. each service in the environment would register itself to the registry, for instance there is this new service called service A, on the startup this service is required to register to the service registry first, so that it is locateable by other services in the environment. Now if service B wants to talk to service A it would go to service registry and service registry would give service B the address of service A so that they can communicate with each other. you see now we would not face any problem if the IP addresses of the service container are dynamic and ephemeral, because whenever the service comes up it is required to register to service registry. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"Health Checks You may be wondering that how does the service registry know that some instance of the service has gone down and now past IP address is no more valid? for that service registry employs some method of service health check. Heart Beat Check some service registeries have a heart beat mechanism built in. service registry sends the periodic heart beats to registered services to know whether they are up or not, if they do not respond then the service IP is deemed invalid. Periodic Registration some service registeries require registered services to register again after a regular interval of time, if they fail to do so the IP address associated with the service which failed to register would be deemed invalid. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"The Types Of service Registry There are two main types of service registries, they differ in a way they go about the process of service discovery, the types are following client side service registery server side service registery Client Side Service Registry Consider the following example. You want to order pizza, you know the place you want to order from but you don’t know how to contact them, you go to google and search for the place and get their number, then you call them and order pizza. This is how the client side service registry works, in this example consider yourself service A the pizza place service B and google service registry. In client side registry you would ask the registry for the IP address and it will give you the IP address and then its you who contact the other service. Server Side Service Registry Consider the following example. You want to contact the CEO of some company, you don’t have the contact information of the CEO but you do know the exchange number of the company, you call the exchange and let them know you want to talk to CEO, they will not give you the CEO’s phone number but instead would forward your call to the CEO themselves. This is exactly how the server side registry would work, service A would contact the registry and tell it that it wants to contact the service B unlike the client side registry it will not give the IP of service B to you instead it will contact service B it self and act like a proxy. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"Well Known Service Registries the following are well known service registries Consul Eureka ETCD Zookeeper ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"In this blog post i discuss, How microservices communicate, and what are the common patterns followed, this post would be a primer, I will go deeper in to the different patterns in future posts","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":" Table Of Contents  Part 1 - Microservices Architecture Deep Dive  Part 2 - API Gateways and Backend For Frontend Pattern  Part 3 - Microservices Communication  you are here  Part 4 - Service Discovery  Part 5- Service Mesh ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"Preface In monoliths the application is divided into modules, those modules serve as logical separation, in microservices the application is divided into services which serve as physical separation, This changes things drastically, before the modules in monoliths used to communicate with each other using the method calls but in case of microservices the services would need to communicate using network calls. This presents different challenges and trade offs, we have to carefully manage these tradeoffs, there are different patterns which the industry leaders in microservices have comeup with which manage the tradeoffs really well in live environments. But still when deciding on the communication patterns for your microservices you have to pay painstaking attention to detail. Because you have to remember these communication patterns are playing with tradeoffs and you have to choose which fits best your design goals and business domain. ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:1:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"The mistake There is a mistake that engineers make very often when they are trying to move to a microservices architecture from a monolith application. They convert the application modules which were present in monolith to the services and then simply try to convert the inter module function calls in monolith to the RPC calls in microservices. This happens because the engineers have wrong assumptions about microservices (or distributed systems). They are still assuming somethings which they assumed for monolithic architecture like they have a reliable network (which is not true, networks are never reliable) and another assumption thy could be making is latency is still zero just like in monoliths, both assumptions are far from truth, and these false assumptions and many other fallacies are coverd in wikipedia entry Fallacies of distributed computing. If you translate all the inter module function calls to RPC calls, your services would be very chatty, which is the last thing we want. In a monolith, network was not being used to communicate unlike microservices, and every call now on the network has a latency which we want to reduce. ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:2:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"Challenges The common challenges in microservices communications include following Network Latency:Network calls are slower than internal function calls. Service Discovery: Services need mechanisms to locate one another dynamically. Fault Tolerance: Failures in communication can cause cascading issues. Data Consistency: Ensuring consistency across distributed services. Security: Protecting communication channels and data in transit. Protocol Complexity: Choosing between REST, gRPC, or message brokers. ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:3:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"Communication Types Client and services can communicate through many different types of communication, each one targeting a different scenario and goals. Initially, those types of communications can be classified in two axes. The first axis defines if the protocol is synchronous or asynchronous: HTTP is a synchronous protocol for communication. The client sends the request and waits for the response to continue. Even if the http requests are being pipelined 1, even then the responses will be in sequence and the client which sent the request has to wait to get the response and would only then continue doing some thing else, you can think of it as a blocking communication mechanism. Protocols like AMQP2 are asynchronous, In this type of communication the client sends the message/request and does not wait for the response from the reciever(s) to continue doing other things (you can think of this like email communication). The second axis defines if the communication has a single receiver or multiple receivers: Single receiver. Each request must be processed by exactly one receiver or service. An example of this communication is the Command pattern. Multiple receivers. Each request can be processed by zero to multiple receivers. This type of communication must be asynchronous. An example is the publish/subscribe mechanism used in patterns like Event-driven architecture. This is based on an event-bus interface or message broker when propagating data updates between multiple microservices through events; it’s usually implemented through a service bus or similar artifact. don’t get bogged down by the different concepts like pub/sub and event-driven architecture, i will go into the detail of how these things work in future posts. A microservice-based application will often use a combination of these communication styles. The most common type is single-receiver communication with a synchronous protocol like HTTP/HTTPS when invoking a regular Web API HTTP service. Microservices also typically use messaging protocols for asynchronous communication between microservices. These axes are good to know so you have clarity on the possible communication mechanisms, but they’re not the important concerns when building microservices. Neither the asynchronous nature of client thread execution nor the asynchronous nature of the selected protocol are the important points when integrating microservices. What is important is being able to integrate your microservices asynchronously while maintaining the independence of microservices. ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:4:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"Asynchronous Integration As mentioned, the important point when building a microservices-based application is the way you integrate your microservices. Ideally, you should try to minimize the communication between the internal microservices. The fewer communications between microservices, the better. But in many cases, you’ll have to somehow integrate the microservices. When you need to do that, the critical rule here is that the communication between the microservices should be asynchronous. That doesn’t mean that you have to use a specific protocol (for example, asynchronous messaging versus synchronous HTTP). It just means that the communication between microservices should be done only by propagating data asynchronously, but try not to depend on other internal microservices as part of the initial service’s HTTP request/response operation. If possible, never depend on synchronous communication (request/response) between multiple microservices, not even for queries. The goal of each microservice is to be autonomous and available to the client consumer, even if the other services that are part of the end-to-end application are down or unhealthy. If you think you need to make a call from one microservice to other microservices (like performing an HTTP request for a data query) to be able to provide a response to a client application, you have an architecture that won’t be resilient when some microservices fail. Moreover, having HTTP dependencies between microservices, like when creating long request/response cycles with HTTP request chains, as shown in the first part of the diagram, not only makes your microservices not autonomous but also their performance is impacted as soon as one of the services in that chain isn’t performing well. The more you add synchronous dependencies between microservices, such as query requests, the worse the overall response time gets for the client apps. In summary if client requests something from microservice A and this service can’t fulfill the request on its own and it talks to microservice B and consequently B needs to talk to microservice C to fulfill the request, then it means that these services are not autonomous. And if the communication between all these services is synchronous , the latency would keep on adding with each request in the chain and if any single service fails in the chain the failure would cascade and the whole chain would fail. As shown in the above diagram, in synchronous communication a “chain” of requests is created between microservices while serving the client request. This is an anti-pattern. In asynchronous communication microservices use asynchronous messages or http polling to communicate with other microservices, but the client request is served right away. If your microservice needs to raise an additional action in another microservice, if possible, do not perform that action synchronously and as part of the original microservice request and reply operation. Instead, do it asynchronously (using asynchronous messaging or integration events, queues, etc.). But, as much as possible, do not invoke the action synchronously as part of the original synchronous request and reply operation. And finally (and this is where most of the issues arise when building microservices), if your initial microservice needs data that’s originally owned by other microservices, do not rely on making synchronous requests for that data. Instead, replicate or propagate that data (only the attributes you need) into the initial service’s database by using eventual consistency. duplicating some data across several microservices isn’t an incorrect design or anti pattern ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:5:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"References pipelining ↩︎ AMQP ↩︎ ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:6:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"In this blog post i discuss the utility of API gateways, what problem they solve? and i will also discuss the importance of BFF pattern","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"API gateway is a common pattern majority of microservices out in the world follow, to address some issues and Backend for frontend is a pattern which is a natural extension of API gateway pattern which helps the microservices scale very smoothly. Table Of Contents  Part 1 - Microservices Architecture Deep Dive  Part 2 - API Gateways and Backend For Frontend Pattern  you are here  Part 3 - Microservices Communication  Part 4 - Service Discovery  Part 5 - Service Mesh ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"The Problem People who are new to learning about microservices architecture and when they first come across the API gateway pattern, naturally they would want to go a little deep into what gateways are, and when they do that they are often confused, because they get different uses and definitions of API gateway that they no longer could figure out what problem is it trying to solve. let me tell you API gateways exist to solve a very specific, single problem which is related to communication between the clients and services, everything else that you hear about API gateways being capable of doing are just some nice sideeffects we use to our advantage. Imagine yourself being a frontend engineer and you are creating the UI for the ecommerce application, you go to the backend engineer and ask him that you are developing the login experience what API endpoint should you use on the client side? and the backend engineer would tell you that the Authentication Service is the one which would handle the login, so they give you the endpoint for authentication service, now after some days you start developing the Cart functionality on the frontend and you get to know from the backend team that, you would need to make use of two more microservices the payment and shipping service to implement that and this continues for the life time of the project. Do you see the problem? The clients are directly communicating with the microservices, utilizing the API exposed by the services, and this is a problem, the client is highly coupled with the backend services, if some endpoint changes the client would need to change too. and coupling is bad as i discussed in my last post. We need an abstraction between the clients and the services, and that abstraction is API Gateway. The API gateways sits between the clients and services and now clients only need to know about the gateway and only talk to it, the clients don’t need to worry about hundreds of services to talk to, gateway will handle that. This also decouples the clients from services, because now microservices can change all they want to change and client won’t need changing because now there is a level of indirection between clients and services. ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"The Side-Effects This communication problem is the primary problem that gateways exist to solve, but now that we have single point of entry to the microservice architecture we have, we can accomplish alot of other good things for our infrastructure. Now that gateway is the entrypoint for our infra we can accomodate the cross cutting features in the gateway itself, because these features are required by all the services in the infra, obviously it would be a madness to implement these for each service individually in different techstacks. Following sections will go into some of the features API Gateways implement (the features which are commonly attributed to API gateways) Authentication This is the major and obvious one, every microservice needs some kind of authentication and identity management, so why do it separately for every service, so the common pattern is to have authentication placed in an Edge Service like API Gateway. Protocol Translation As i did discuss in the last post one of the advantage of having microservices is flexibility with choosing the technology for the implementation of the service, one microservice can have an REST api, one could have graphQL the other could have a grpc implemented. If clients want to talk to them, they have to speak all these languages (protocols) to implement the client side successfully which is madness. So API gateway solves this problem as well by sitting between the services and clients, it acts as a protocol interpreter because as services are only talking to the gateway they only need to speak one protocol mainly REST and API gateway would take care of talking to diverse services in diverse protocols. Rate Limiting Another cross cutting concern is rate limiting, API gateway can implement the cutting edge rate limiting algorithms on the edge instead of these algorithms being part of every service which saves us from redundancy. Request Routing and Load Balancing API gateway is also responsible to Route incoming API requests to appropriate backend services based on the request path, headers, or other criteria. API gateway is also used to implement the load balancer for the services to Distribute traffic across multiple service instances for high availability and load balancing. Caching API gateway is naturally a good candidate for caching the service responses to reduce latency. Monitoring And Logging API gateways being the entrypoint are very suitable for the implementation of monitoring and logging solutions. whenever the gateway comes into action simply log the stuff and trigger the monitoring middleware. Others Some other common functionalities of API gateways include Service discovery Security features CORS policies API versioning ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"How to scale Now i am sure one question must have popped in your mind, that wouldn’t the API gateway become a bottle neck as all the traffic is going through the gateway and it is acting like a funnel? you are right! there is a potential of gateway becoming a bottle neck, but there is a simple solution. We can horizontally scale the API gateway and then put a load balancer in front of it, now the clients request will come to load balancer first and then the load balancer will distribute the request among the gateways. ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"Backend For Frontend The Problem During the whole blog post i have been mentioning the word “Client”, but the client itself is a generic term and it could be many things like a client could be a PC, a mobile, an IOT device or another microservice. All these clients are different in many ways, a PC for instance has all the resources in abundance like big screen, alot of memory, big compute power e.t.c, mobiles on the other hand have small screen real estate, small memory, small compute and also limited power supply. This is the reason the backend APIs they are consuming have to be tailor made because all these clients have their own strengths and weaknesses and our goal as engineers is to exploit their strengths and mitigate the weaknesses as much as we can. The mobile clients and PC clients have different resources hence they can’t just have same API endpoints available to consume, mobile clients show limited data and try to make as few HTTP round trips to fetch data as possible because each http request drains battery and increases latency, technology like graphql is more suitable for mobiles then the HTTP REST api. Following is the depiction of difference between simple API Gateway and the gateways following the BFF architecture You see now all the clients have a tailored gateway now they will get what they need in the most efficient way possible. All the data fetching and then aggregation will now move to the tailored gateway and the client will focus on the frontend logic only. ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"Useful Links sam newman BFF amazon api gateway microsoft api gateway architecture ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:5","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"This blog series is all about microservices, we will start with simple definition of microservices and and go all the way to know how to implement them effectively and when do they make sense and when is it a stupid idea to implement microservices","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices are one of the most popular methodology to develop and deploy the software systems. In popularity it is only second to Monoliths (or Modular Monoliths). This blog series is all about microservices, how do they differ from monoliths, what are their pros and cons, when do they make sense and how to implement microservices effectively. Table Of Contents  Part 1 - Microservices Architecture Deep Dive  you are here  Part 2 - API Gateways and Backend For Frontend Pattern  Part 3 - Microservices Communication  Part 4 - Service Discovery  Part 5 - Service Mesh ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: The Inception Microservices don’t have any precise inception date, but rather evolved over time. It gained prominence around 2011 largely due to shift towards cloud and distributed computing. following are the things which led to microservices ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Service Oriented Architecture (SOA1) Microservices evolved as a refinement of SOA, which focused on creating loosely coupled, reusable services , but SOA had some severe afflictions like heavy middleware and complexity to name a few. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Cloud Computing The growing adoption of cloud platforms like aws highlighted the need for smaller, more independent services (by the way it was companies like aws which pioneered the breaking down of monoliths into smaller services) ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Martin Fowler and James Lewis’s Definition In 2014 in their influential article, titled “Microservices: A Definition of This New Architectural Term”, Fowler and Lewis codified the principles and patterns of microservices. This was pivotal in standardizing the concept and its terminology. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Early Adopters And Case Studies Companies like Netflix and Amazon implemented microservices early, demonstrating its effectiveness in scaling and adapting to dynamic workloads. Netflix’s architecture shift started in the late 2000s and became a famous case study for microservices. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: A Definition While there is no precise definition of this architectural style, there are certain common characteristics around organization around business capability, automated deployment, intelligence in the endpoints, and decentralized control of languages and data. This is how martin fowler describes microservices, and in my opinion he is on point. The goal of this blog post is to discuss these characteristcs that make up microservices that he is talking about. And in subsequent blog posts i will go deep in to the tools which the Engineers use to work with microservices effectively. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:2:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: The Characteristics ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Preface Microservices are independently releaseable services which are modeled around the business domain (e.g an ecommerce web application will have services like inventory, order management and shipping), each service exposes the API so that other services can use its functionality, but the implementation details remain hidden, once we have small services the more complex bigger system could be built using these small services like a lego. Information hidding2 is very important for microservices to work, every service hides as much information as possible from other services because that would make sure that in future if a microservice needs to change it can change without effecting the other services using this service which is subject to change. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Independent Deployability This refers to the characteristic of a service, in which you can change a service in some way and deploy it and the new feature or change is now available to the software’s users, you don’t need to change any other service, there are no cascading changes. some examples of changes would be , a small bug fix , api endpoint changes , addition of a whole new feature or a database schema change. Achieving this level of decoupling in a real world system is extremely difficult and engineers in the real world could relax this rule of microservices. nonetheless this is the most important characteristic of microservices, if you are able to achieve independent deployability for your application, you have already solved alot of problems which microservices promise to solve. And if you focus on this characteristic as the out come you would achieve numerous other benefits of microservices because independent deployability could only be achieved if you get alot of other things right. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Services Owning there Own State (aka every service having its own database) This characteristic was synonymous to microservices few years ago , it went without saying that microservices should have their own databases each, but for the past few years it has become a point of contention, and people tend to challenge this rule more and more, the reason for contention is this that this rule does solve alot of problems but also create many of its own as well, like Distributed Transactions, which are very hard to get right. This characteristic suggests that if service A needs some data from the database of some other microservice B, it should ask microservice B through its API to hand over the data and not share the database, this way the services will have control over what is visible to other services and what is not and access to data would be limited, and if the access to the data is limited by the API requests then service B can keep on changing e.g the schema of the database or even replace the whole database and jump from sql to no-sql database even than service A would not need to change because the API which service B is providing is the same. If we want our services to be independently deployable we need to promote backward compatibility and limit the backward incompatibility, Its that simple, but hard to achieve because you need to have a very vivid vision for the service you are designing, and you have to think in much advance what to expose and what not to expose to other services, If you make some change to a service A which is backward incompatible with the services consuming service A , all the consuming services are forced to change, so “services owning their own state” is aiming to promote backward compatibility. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"What About Size This is one of the most discussed topic in the microservices arena , what should be the size of a microservice? obviously there could be many answers to this question, one answer which i have heard is “this is something which should be subjective”, I don’t agree with this because if microservice’s size is being determined by a person’s (or multiple people’s) subjectivity then there would be hundreds of engineers and project managers who would work on the microservice during its life time, whose subjectivity should the team adhere to. there are other answers which do make sense like “microservice should be as big as your head” which means that microservice should be big enough so that a person working on it can fit it in his/her head, they should have complete idea how the microservice works, what are its interfaces, how is it internally coupled, whats exists where e.t.c. This definition of size is also somewhat contentious, because every person’s ability to fit things in his or her head is different. this idea of a systems being as big as a persons head is not new, it was one of the goals of OOP as well, you design classes and encapsulate the functionality, exposing small interface of the class and giving class a name , now whenever the programmer needed to reason about the code in his head or in communication with someone else instead of mentioning the whole functionality and interface the person can alias it with the name of the class. interesting isn’t it? The Best definition of size would be, “A microservice should have as small of an interface as possible”, and this is very self-explanatory. And this aligns with information hiding aspect i have just mentioned. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Design For Failure One characteristic that martin fowler lists is designing the services for failure, but what does this mean? Well this means that at every point of a microservices design we should be assuming that the failure can happen and handle the failure accordingly. This is one of the side effects of breaking the monolith down into services, Because before the application was a single process monolith and now the monolith has become different services residing in different processes maybe on different computers and when they communicate failures could occur. Whole projects and methodologies have emerged because of this, projects like grpc is a RPC3 framework which handles all the boilerplate for fault and error handling for the services, so you don’t have to right the boilerplate and can focus on the logic of the service, and methodology like chaos testing has emerged to rigorously test the services in hostile circumstances. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:5","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Smart Endpoints And Dumb Pipes This characteristic suggests that, the communication channels between microservices should do the bare minimum which is communicate and thats it and all the other shenanigans should be left to the services which are communicating. This is a lesson we have learned from microservices predecessor “Service Oriented Architecture” which used ESB (Enterprise Service Bus) for communications which was a fully loaded communication system, and this ESB is what lead to the demise of SOA REST is prime example of this, it is a very dumb protocol, service A sends request to service B, service B gets the response ready and sends back the response, plain and simple, REST does not introduce any kind of magic, it prefers being dumb and just gives us simple rules to abide by. The messaging queues are another good example which contribute to the service communication without being too smart, they are simple queue datastructure implementation which come with certain guarantees and aid services with async communication. I will go deep into messaging queues in the future blog post about sync and async communication. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:6","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: Monolith To Microservice Decomposition Patterns It is not possible to break the monolith down into Microservices in a day, its a complex process which takes alot of thinking and planning on engineers part, but as the time has went by and more and more big companies like netflix , uber and aws have adopted microservices, they have comeup with patterns of decomposition which are now battle tested and work really well, so engineers need to know those patterns so they don’t reinvent the wheel, following i will list down some patterns and i will discuss some of them in the future blog posts. strangler fig pattern domain driven design Event driven decomposition database splitting backend for frontend ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:4:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: Advantages ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Flexibility With Technology Choice This is one of the best pro of having microservices architecture, you can choose to develop every service with different tech stack, for instance you can use a database for a service which is suitable for the service workload and now you are noot shackled by the monolith, e.g if the workloads for the service are write heavy, you can use a DBMS which uses LSM tree as an internal datastructure but if the workload is read heavy you can use B-Tree based DBMS, same story repeats for the columnar or row based databases. In the same way you can choose the implementation language for the service on different criterias, Golang if you want good out of the box concurrency and python if good library support is needed and concurrency is not much of a concern. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Robustness Microservices are more robust compared to monoliths, if monolith application fails the system fails, in case of microservices a single service could fail for some time but the whole system does not come down crumbling, if the failure is not cascading. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Scaling Just like microservices are invidually deployable, they are also individually scaleable, and thats a big deal, in case of monoliths you need to scale the whole application even if small part of the application needed scaling Imagine an e-commerce platform with the following functionalities: User Service: Handles user authentication and profile management. Order Service: Manages order placement and history. Inventory Service: Tracks product stock. Recommendation Service: Provides personalized product recommendations. In a monolithic architecture, all these services are part of a single application. If product recommendations experience a spike in demand (e.g., during a sale), the entire monolith must scale, even though only the Recommendation Service requires more resources. In a microservices architecture, these functionalities are separate services. Each can be independently scaled based on demand: During a sale: Recommendation Service: Scales to handle the increased load, spinning up additional instances. User Service, Order Service, and Inventory Service: Remain unaffected and do not incur extra costs. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Ease Of Deployment Imagine changin one line in million line monolith application and redeploying, thats too much risk and apart from that you would also need to run all the tests hoping that the change has broken nothing. Now on the other hand microservices are small code bases and changes and deployments both are fast and even if anything breaks its easy to trace and fix. you can comeup with alot more advantages of microservices but these are the main advantages which entice mojority engineering teams to invest time and effort to migrate to microservices architecture ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: Disadvantages ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Developer Experience One of the main pain points of developing a microservices architecture is terrible developer experience, because it is very difficult to mimic the runtime environment locally, your single computer can only run fraction of total microservices. and if you are developing in the cloud thats even worse because the feedback cycles are longer. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Technology Overload There are like 50 solutions for the same problem in the market and every engineering team is using different tools to solve the same problem in different companies,so the engineers have to keep up with the tool evolution ever so often, which is very demanding for example there are 20 tools to create a service mesh which i can name off the cuff right now, but all of them are doing the same thing (there internal implementation details could differ). secondly the advantage of flexibility with the technology could turn into a disadvantage quickly, because you have so many technology choices to solve a problem that you can suffer with choice paralysis and that could consequently postpone the decisions. and lastly you can gradually keep on adding new tools to the project like you start with docker swarm and then gradually shift to kubernetes and the same way you keep on adding tools, and when there is new onboarding on the team the new person would be terrified watching so many unnecessary tech being used, and that could effect the team productivity. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Monitoring And Debugging In monoliths there is single application running on the single server and that makes it very easy to monitor it and debugging the problems, because the life of a query is so simple, the client makes a request and the single server responds to the request, that is it. But in case of microservices the life of the query gets exponentially bigger with the number of microservices communicating to full fill the query. consequently if there is some problem in the system its very difficult to pin point where the problem really is, and it is also very hard to monitor the whole system and get a holistic view of things, below the image is depicting a problem in microservices called Big ball of mud, it refers to the communication between different microservices as big ball of mud, and it sure is ball of mud, now you can imagine why it is so hard to monitor and debug microservices ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Security With a single-process monolithic system, much of our information flowed within that process. Now, more information flows over networks between our services. This can make our data more vulnerable to being observed in transit and also to poten‐ tially being manipulated as part of man-in-the-middle attacks. This means that you might need to direct more care to protecting data in transit and to ensuring that your microservice endpoints are protected so that only authorized parties are able to make use of them. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Latency With a microservice architecture, processing that might previously have been done locally on one processor can now end up being split across multiple separate micro‐ services. Information that previously flowed within only a single process now needs to be serialized, transmitted, and deserialized over networks that you might be exer‐ cising more than ever before. All of this can result in worsening latency of your system. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:5","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Data Consistency Shifting from a monolithic system, in which data is stored and managed in a single database, to a much more distributed system, in which multiple processes manage state in different databases, causes potential challenges with respect to consistency of data. Whereas in the past you might have relied on database transactions to manage state changes, you’ll need to understand that similar safety cannot easily be provided in a distributed system. The use of distributed transactions in most cases proves to be highly problematic in coordinating state changes ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:6","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Useful Links Microservices at netflix DoorDash scaling microservices Snap chat’s journey from monolith to microservices ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:7:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Book Recommendation Read the brilliant book by Sam Newman called building microservices4 ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:8:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"References what is service oriented architecture ↩︎ information distribution aspects of design methodology ↩︎ Remote procedure calls ↩︎ Brilliant book: building microservices ↩︎ ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:9:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"}]