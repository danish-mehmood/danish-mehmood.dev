[{"categories":["networking"],"content":" Table Of Contents ¬†Part 1 - Introduction to TLS ¬†Part 2 - Crytography Primitives ¬†Part 3 - Public Key Infrastructure ¬†you are here A lot of we have discussed so far seems to overlap, the purpose of this post is to delineate what we have learned so far so that you understand how all the parts fit together in TLS. consider this a mini-review. The above diagram is very helpful in clearing the confusion, as you can see hashing provides integrity and authentication, symmetric encryption provides confidentiality, and asymmetric Encryption provides all three, namely integrity, authentication, and confidentiality (if you are not sure how? go read the last post in the series). But the question is which one to use? The better question is when to use which one? as I wrote in the last post hashing and symmetric encryption are better for bulk data to provide integrity, confidentiality, and authentication, whereas asymmetric encryption is suitable for **_limited data _**to provide all three services. ","date":"2025-01-02","objectID":"/tls-deep-dive-part-three/:0:0","tags":["networking","security"],"title":"Tls Deep Dive Part Three","uri":"/tls-deep-dive-part-three/"},{"categories":["networking"],"content":"Let‚Äôs Deep Dive suppose the client and the server want to exchange bulk data and to make sure the confidentiality and integrity of that data they need to establish a mutual secret key. Well secret key is a small amount of data, the prudent thing to do here would be to use asymmetric keys to exchange this secret key between the client and the server. and after the key exchange, the client and the server start to exchange data. There is a problem though, anyone on the internet can generate a pair of asymmetric keys, even you sitting on your computer can generate a pair using OpenSSL, it will hardly take 30 seconds, so how to make sure that the server you are talking to is blue.com or google.com and not someone else masquerading as them? ","date":"2025-01-02","objectID":"/tls-deep-dive-part-three/:1:0","tags":["networking","security"],"title":"Tls Deep Dive Part Three","uri":"/tls-deep-dive-part-three/"},{"categories":["networking"],"content":"Public Key Infrastructure This is the point where a certificate authority comes in, it‚Äôs an entity that the client and the server both trust. A certificate authority simply links asymmetric key pair to a specific identity, It provides a certificate that proclaims that the private key associated with the public key in this certificate is blue.com or google.com. But how do we know that the certificate is legit? and that it is generated by the authority we trust. well, that‚Äôs easy, the CA will digitally sign the certificate and if the client would be able to decrypt the certificate with the public key that it trusts, it would know that the certificate is legit. as you can see in the diagram above, this communication scenario creates a triangle, with the client, the server, and the CA on the vertices, this triangle of trust is known by a fancy name Public Key Infrastructure. ","date":"2025-01-02","objectID":"/tls-deep-dive-part-three/:2:0","tags":["networking","security"],"title":"Tls Deep Dive Part Three","uri":"/tls-deep-dive-part-three/"},{"categories":["networking"],"content":" Table Of Contents ¬†Part 1 - Introduction to TLS ¬†Part 2 - Crytography Primitives ¬†you are here ¬†Part 1 - Public Key Infrastructure In my last blog post, I tried to put TLS in a context in which it is easier to see why TLS is needed in the first place, what problems it solves, and what services it provides to make our communication over a public network secure. In this blog I want to tell you about some cryptography principles behind TLS, it is a prerequisite to grok TLS, in this blog post I will write about hashing algorithms,**HMAC, Encryption, public-private**keys, etc. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:0:0","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Hashing Algorithms üßÆ Hashing algorithms are a category of algorithms that take input of arbitrary length and output a string of fixed length. Hashing is ubiquitous in computer science, it has so many applications and is a useful category of algorithms. let me describe a very basic hashing algorithm, suppose I have a hashing algorithm that takes in a string ‚Äúhello‚Äù and outputs the sum of the numbers at which every letter of the string occurs in the alphabetical order. so if the input is ‚Äúhello‚Äù the output would be 8 + 5 + 12 + 12 + 15 = 52. likewise, you can see the output for any given input, it‚Äôs a very simple implementation. although this example algorithm is good for example purposes but is a horrible hashing algorithm, you would be thinking how could someone categorize hash functions as good or bad, the answer is good hashing algorithms should follow the following 4 rules Infeasible to produce a given digest. Impossible to extract the original message. Slight changes produce a big difference in the output. The size of the output should be fixed. if you try to filter the hashing algorithm we discussed through these 4 rules, it won‚Äôt check a single rule, which is why it is a terrible hashing algorithm. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:1:0","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Hands-On Next, I would demonstrate a good hashing algorithm called sha-256. If you want to follow along and have Linux then open up the terminal and follow along otherwise you can use an online sha-256 generator. as you can see when I gave ‚Äúhello‚Äú as an input to the sha256sum Linux utility it outputs a random string. if you give the same input you will get a similar output as me. as sha-256 is a good hashing algorithm and is being used in the real world, it follows all 4 rules I stated. it is close to impossible to generate all the inputs given the output or the other way around, telling the input which generated the specific output, it also satisfies the rule of output being of specific size, sha-256 given input of any size would always output a string of size 256 bits. it also satisfies the rule which states that a small change in input should result in a big change of output, see the following example. Only introducing a period at the end of the last input has changed the output drastically (this is called an avalanche effect) from, 5891b5b522d5df086d0ff0b110fbd9d21bb4fc7163af34d08286a2e846f6be03 to 5d382abfb5da6294d05e4afade40adcdfc85ac56a6a2e6d94b9734c41c6ddbf3 ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:2:0","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Collisions üí• üèé collision occurs when two different inputs map to the same output, to understand collisions consider the following example, suppose we have a hash function that takes arbitrary input and outputs fixed size three bit string. the total unique strings that our function would be able to output would be 23= 2 √ó 2 √ó 2 = 8. which is very small if we give our function 9 different inputs the two inputs are bound to map to the same output string. this is called collision, and it is inevitable when you have output of a fixed size but in the case of good hashing algorithms like sha-256 which has 256-bit size output, it is very unlikely to happen because 2^256 is a humongous number. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:3:0","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Integrity, Authentication And HMAC: Integrity as I explained in the last post is a property of data reaching the recipient as it leaves the sender, unchanged. TLS uses hashing to achieve integrity. consider the following scenario. blue user wants to send a message to the green user over the internet and also wants to ensure the integrity of the message. for that blue user does not only send the message but also the hash of the message to the green user, the green user gets the message and hash, hashes the message, and compares the produced hash with the hash sent with the message by the blue user and if the hashes match the green user would know that the message hasn‚Äôt been changed. Do you notice any problem in this flow? It‚Äôs quite easy to spot. the man in the middle could easily get the message as well as the hash, change the message append the hash of a modified message, and send it to the green user and the green user would never know that the message was changed in transition because the message and the hash would match at his end. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:4:0","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"HMAC And Authentication To overcome this problem, before sending any message green and blue user agree on a key (we will go deep into this, how this is done for now just know that they exchange a key), then when they are sending a message they don‚Äôt only hash the message they want to send, instead they hash both message and the key together and then send the message towards the other side, the remaining flow remains the same. the result of hashing the message and the key is called message authentication code, notice that the parties don‚Äôt only need to agree on the key but also how they are going to hash the key with the message because remember, appending the key to the message then hashing and putting the key before the message then hashing would result in different hashes. to make sure these things don‚Äôt become a reason for conflict there is a whole RFC standard that guides and standardizes the process called HMAC. there is one more thing you need to notice, HMAC does not only provide integrity it also provides authentication because when you are putting the key with the message and then hashing, the recipient wouldn‚Äôt only be sure of the integrity of the message but also they would know that this message could only be sent by the person who has the key (which was exchanged in the beginning of the process). So HMAC is how TLS achieves integrity and authentication. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:5:0","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Encryption üî¢: As we discussed in the last post TLS also provides confidentiality, it uses encryption to achieve the goal of confidentiality. Encryption is a very simple affair, you take an input, feed it to some encryption algorithm, and get the output, in the case of encryption the input is called plain text and the output is called cipher text. the simple encryption in which you don‚Äôt use any key and just shuffle the plain text to get the cipher text is not scalable, because to send the message to every different person you would need to come up with a new algorithm to encrypt. this is the reason we use key-based encryption in which the algorithms are known to everyone but the keys used are private. using this approach we can use different keys with the same algorithm and the cipher text will not break. there are two ways to do the key-based encryption, one is asymmetric cryptography and the other is symmetric cryptography. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:6:0","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Asymmetric cryptography: in this type of cryptography, you have two pieces of keys one is public and the other is private, one you could use for encryption and the other for decryption. these two keys are mathematically related, if you encrypt with one key only the other key in the pair could decrypt it. asymmetric cryptography has some weaknesses, it is compute intensive it takes a lot of compute power to encrypt and decrypt, and secondly the cipher text is large compared to plain text. it also has a very useful pro, which is the private key is never shared with anyone, it always remains with the user and public key could be known by anyone, it does not matter. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:7:0","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Symmetric cryptography: in a symmetric crypto setup we only have one key which is used for both encryption and decryption, and this has an inherent weakness as we would need to share the key and anyone can capture it in transit, symmetric cryptography is very fast at working on large amounts of data and the cipher text it produces is equal in size to the plain text. For bulk data, symmetric crypto is used and for small amounts of data asymmetric crypto is used Public-Private Key Encryption üîë: let‚Äôs try to understand the use of private and public keys in TLS in a more coherent way. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:8:0","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Confidentiality: suppose Jim wants to send Pam a message and wants confidentiality, what he would do is encrypt the message using ‚ÄúPam‚Äôs public key‚Äù and send the message over the wire, as the message was encrypted using Pam‚Äôs public key, only Pam‚Äôs private key could decrypt and only pam can read it hence confidentiality is achieved. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:8:1","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Authentication (digital signatures) and Integrity üñä: now consider another scenario where Jim wants to send Pam a message and does not care about confidentiality but wants Pam to know that the message was indeed sent by him, to achieve this he would now use his private key to encrypt the message and when the message would reach pam she could only decrypt using Jim‚Äôs public key that she has and now she would know that the message is from him. this technique is called digital signatures. because the user is using encryption to prove his or her identity. but notice that digital signatures also have a side effect which is ‚Äúintegrity‚Äù. because when Pam was able to decrypt the message successfully she also got the confirmation the message was not modified in transition because if it was changed then she won‚Äôt be able to decrypt it. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:8:2","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":"Hybrid Encryption: In the real world, the two kinds of encryption are not used in isolation, but they are used together because they complement each other so well and cancel each others weakness‚Äôs remember that asymmetric cryptography is not feasible for bulk data and symmetric crypto is. and that asymmetric crypto is safe in a way that private keys are never shared and symmetric cryptography has a drawback that we need to share the same key among users and there is a danger of a secret key being captured in transit. well in the real world, a hybrid model is used in which asymmetric cryptography is used to exchange the keys and then further communication among the involved parties is encrypted and decrypted using symmetric keys. This way we get best of both worlds. What about the signatures then? as we have discussed before asymmetric encryption is used to digitally sign messages but with a single key in the symmetric crypto signatures are not possible. and asymmetric crypto is not good for large amounts of data so how do we sign data to prove the identity? we can use the smaller version of the message for signature purposes, this is where hashing comes in, we can hash the message first and then sign it using a private key, and add it to the message, then the recipient can decrypt using public key getting the hash, then hashing the original message and comparing the two hashes would know the sender is the expected one. this achieves once again authentication and integrity. This is it for this blog entry in future posts I will go deeper into the implementation and consequences of TLS. I hope now you have understood what role encryption and hashing plays in TLS and how everything fits together. ","date":"2024-12-29","objectID":"/tls-deep-dive-parttwo--cryptography-primitives/:8:3","tags":["networking","security"],"title":"SSL/TLS deep dive part 2: cryptography primitives","uri":"/tls-deep-dive-parttwo--cryptography-primitives/"},{"categories":["networking"],"content":" Table Of Contents ¬†Part 1 - Introduction to TLS ¬†you are here ¬†Part 2 - Crytography Primitives ¬†Part 1 - Public Key Infrastructure Disclaimer: I will use the term TLS instead of SSL in this blog to get rid of me writing and you reading ‚ÄúSSL/TLS‚Äú again and again, TLS and SSL are different versions of the same protocol and TLS is the one in use. ","date":"2024-12-28","objectID":"/tls-deep-dive/:0:0","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["networking"],"content":"What This Blog Post Is About This deep dive would be a one-stop guide for anyone trying to grok Transport layer security. This guide will be broken down into multiple blog entries ‚Äúthis‚Äú being the first of many, so that no one reading this deep dive gets overwhelmed or bogged down by details. this strategy provides necessary pauses and enough time for anyone to assimilate the provided information. TLS/SSL is not hard to understand but there is so much to cover, to understand TLS we first need to provide a wider context for it, persevere through this deep dive and I guarantee you will understand TLS. This blog series will cover more or less following topics what problem does TLS solve, what are the primitives, what claims does it make, what is a public-private key, what is a digital signature, what are certificates, certificate authorities, certificate chains, replay attacks, non-repudiation, public key infra, integrity, TLS versions and more‚Ä¶ let‚Äôs dive ü§ø‚Ä¶.. ","date":"2024-12-28","objectID":"/tls-deep-dive/:1:0","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["networking"],"content":"The Problem And The Solution ","date":"2024-12-28","objectID":"/tls-deep-dive/:2:0","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["networking"],"content":"Internet, HTTP, and HTTPS keep in mind that the above image is good for understanding the technology at hand but it is a model and not the reality so view it abstractly while reading further. The Internet is a big network of interconnected routers (not only routers but let‚Äôs simplify) as you can see in the above image. the job of this internetwork is to take the data packets from node at point 1 to node at point 2. consider a client requests the server for an HTML page, the server will prepare the HTML and send it back to the client and the client will display the HTML. there are 2 very simple yet nontrivial points you have to keep in mind regarding this communication üìë There is no encryption involved in this very simple communication I described And once the data leaves the client or the server, the client and server lose control of the data, It is the job of the internet to route data however it wants note that the majority of the traffic on the internet is from websites and websites don‚Äôt always present information, sometimes they want to retrieve information from the users as well. for example passwords or bank information. communicating such information between the nodes using the aforementioned model of communication would be stupid, as anyone between the client and server could eavesdrop and read what is being sent. Do you see the problem? üéØ This is the problem TLS is trying to solve, TLS before communicating anything on the internet creates a secure tunnel through which the information flows. HTTP which uses TLS is called HTTPS, there is no other difference, but HTTP is not the only protocol for which TLS is tailored, TLS is generic and it does not care about the protocol underlying it, some other applications of TLS include FTPS and TLS VPN using which you can use your company‚Äôs network sitting at home. ","date":"2024-12-28","objectID":"/tls-deep-dive/:2:1","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["networking"],"content":"How Does TLS Accomplish Data Security? Note: It is very important to understand two things TLS does not literally create a tunnel because as you may or may not know internet uses a model called packet switching to transfer data ( basically in a packet-switched network every data packet takes a different route instead of taking one dedicated route ). So how could TLS create a tunnel? second TLS does not encrypt the underlying protocol headers as TLS operates on the Transport layer it won‚Äôt encrypt the TCP or IP headers but rather it would encrypt the payload like passwords or bank information ","date":"2024-12-28","objectID":"/tls-deep-dive/:3:0","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["networking"],"content":"What Should TLS Do To Data To Make Communication Safe?üì° Recap, when I said the data leaves the node, it is not in our control anymore, anyone can read our sent data, someone reading our data on the wire is called a man-in-a-middle attack, remember TLS can not just prevent the man-in-the-middle from getting the packets but it can encrypt the data captured by middle man to render it useless to the middle man. TLS provides 3 main services 1. Confidentiality: only the entities for whom data is meant could read the data, this service is provided using encryption. 2. Integrity: data is not susceptible to change on the wire it should reach the recipient as it left the sender (no changes not even an extra period or space ), this service is provided by hashing. 3. Authentication: the third and last service of TLS is to make sure that people or parties are who they claim to be, this service is provided using public key infrastructure. To understand these services we need to first discuss some cryptography primitives which I will write about in the future part of this blog series. ","date":"2024-12-28","objectID":"/tls-deep-dive/:4:0","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["networking"],"content":"Some Web-related Attacks For Perspective ","date":"2024-12-28","objectID":"/tls-deep-dive/:5:0","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["networking"],"content":"TLS Is Anti-Replay: Replay attacks are very common on the web in which a malicious user could intercept the user‚Äôs requests and later on replay those requests to achieve some bad motives. For example, if the user is using a bank website to transfer funds of $100 and the man in the middle captures the request and replays to request multiple times to empty the user account TLS prevents these kinds of attacks using sequence numbers for every request and if the request with the same sequence number is repeated it is rejected. ","date":"2024-12-28","objectID":"/tls-deep-dive/:5:1","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["networking"],"content":"TLS Promotes Non-Repudiation: Google defines repudiation in the following way to refuse to have anything to do with If someone sends you something on the internet and later refuses to accept that they sent you anything , this won‚Äôt be possible because of 2 services that TLS provides namely Integration and Authentication. ","date":"2024-12-28","objectID":"/tls-deep-dive/:5:2","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["networking"],"content":"The End This is it for this blog entry in future posts I will go deeper into the implementation and consequences of TLS. giving all this context before going deep was very important to cement the understanding I hope now you have understood the motivations for having a protocol like TLS and looking forward to understanding more deeply. ","date":"2024-12-28","objectID":"/tls-deep-dive/:6:0","tags":["networking","security"],"title":"SSL/TLS Deep Dive","uri":"/tls-deep-dive/"},{"categories":["microservices"],"content":" Table Of Contents ¬†Part 1 - Microservices Architecture Deep Dive ¬†Part 2 - API Gateways and Backend For Frontend Pattern ¬†Part 3 - Microservices Communication ¬†Part 4 - Service Discovery ¬†Part 5 - Service Mesh ¬†Part 6 - Distributed Transactions ¬†you are here ","date":"2024-12-26","objectID":"/microservices-architecture-deep-dive-part-six-distributed-transactions/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Six: Distributed Transactions","uri":"/microservices-architecture-deep-dive-part-six-distributed-transactions/"},{"categories":["microservices"],"content":"What Is A Transaction? A database transaction symbolizes a unit of work, performed within a database management system (or similar system) against a database, that is treated in a coherent and reliable way independent of other transactions. A transaction generally represents any change in a database. In a database management system, a transaction is a single unit of logic or work, sometimes made up of multiple operations. Any logical calculation done in a consistent mode in a database is known as a transaction. One example is a transfer from one bank account to another: the complete transaction requires subtracting the amount to be transferred from one account and adding that same amount to the other. A database transaction, by definition, must be atomic (it must either be complete in its entirety or have no effect whatsoever), consistent (it must conform to existing constraints in the database), isolated (it must not affect other transactions) and durable (it must get written to persistent storage).Database practitioners often refer to these properties of database transactions using the acronym ACID. ","date":"2024-12-26","objectID":"/microservices-architecture-deep-dive-part-six-distributed-transactions/:1:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Six: Distributed Transactions","uri":"/microservices-architecture-deep-dive-part-six-distributed-transactions/"},{"categories":["microservices"],"content":"The Problem In a monolithic architecture getting the transaction ACID properties right was already very difficult. People from the past and the present have worked tirelessly to make the database transactions ACID. But now we have an entirely different problem regarding database transactions. Now we have a distributed microservices architecture in which every service has its own database, but for the end user all these microservices combine and make up a single service and the end user can not tell the difference. Thats the end goal of distributed systems. But Now what previously needed to be ACID transaction on a single database has to be ACID over multiple microservices databases. ","date":"2024-12-26","objectID":"/microservices-architecture-deep-dive-part-six-distributed-transactions/:2:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Six: Distributed Transactions","uri":"/microservices-architecture-deep-dive-part-six-distributed-transactions/"},{"categories":["microservices"],"content":"Distributed Transaction A distributed transaction operates within a distributed environment, typically involving multiple nodes across a network depending on the location of the data. A key aspect of distributed transactions is atomicity, which ensures that the transaction is completed in its entirety or not executed at all. It‚Äôs essential to note that distributed transactions are not limited to databases. Databases are common transactional resources and, often, transactions span a couple of such databases. In this case, a distributed transaction can be seen as a database transaction that must be synchronized (or provide ACID properties) among multiple participating databases which are distributed among different physical locations. The isolation property (the I of ACID) poses a special challenge for multi database transactions, since the (global) serializability property could be violated, even if each database provides it. ","date":"2024-12-26","objectID":"/microservices-architecture-deep-dive-part-six-distributed-transactions/:3:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Six: Distributed Transactions","uri":"/microservices-architecture-deep-dive-part-six-distributed-transactions/"},{"categories":["microservices"],"content":"The Consistency Challenges Distributed transactions are more complex than transactions on a single-instance database because we need some way to ensure that each database node is consistent with the others. The diagram below illustrates one potential problem with distributed transactions. Imagine we have an application attempting to commit a transaction to three separate database nodes (perhaps the same data is replicated on all three nodes, or perhaps the transaction affects multiple rows, and the different rows are stored on different nodes). In the diagram, the transaction is successfully written to the first two nodes, but fails to write to the third ‚Äî perhaps due to a network disconnection or an error on the node itself. This introduces a state of inconsistency ‚Äî the first two nodes and the third node ‚Äúdisagree‚Äù about what data is correct. Needless to say, inconsistency in a database can cause all kinds of problems, particularly when it comes to the kinds of workloads that use transactions (payment processing systems, for example). So, how can we ensure our database remains consistent even when it is partitioned across multiple nodes? There are a variety of approaches, each with its own advantages and disadvantages. Let‚Äôs take a look at some real-world examples of workable patterns for distributed transactions. ","date":"2024-12-26","objectID":"/microservices-architecture-deep-dive-part-six-distributed-transactions/:4:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Six: Distributed Transactions","uri":"/microservices-architecture-deep-dive-part-six-distributed-transactions/"},{"categories":["microservices"],"content":"The Solution In the following paragraphy i will explain the ways in which distributed transaction are done in the wild using an example. ","date":"2024-12-26","objectID":"/microservices-architecture-deep-dive-part-six-distributed-transactions/:5:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Six: Distributed Transactions","uri":"/microservices-architecture-deep-dive-part-six-distributed-transactions/"},{"categories":["microservices"],"content":"Example System: Travel Booking Scenario: A user books a vacation package. The process includes: Flight Service: Books a flight. Hotel Service: Reserves a hotel room. Car Rental Service: Reserves a rental car. Each service operates independently but must work together to fulfill the booking. A failure in any service should result in a rollback. Orchestration And Choreography 1. Orchestration In orchestration there needs to be a coordinator (a central controller ) which manages the entire workflow. How it works: The Travel Booking Orchestrator service calls the Flight, Hotel, and Car Rental services in sequence. If a failure occurs (e.g., flight booking fails), the orchestrator initiates compensating actions (e.g., cancel hotel and car reservations). Flow: User sends a booking request to the orchestrator. Orchestrator calls the Flight Service. If successful, it calls the Hotel Service. If successful, it calls the Car Rental Service. If any service fails, orchestrator rolls back previous bookings. Advantages: Centralized control simplifies monitoring and debugging. Easier to implement retries and compensations. Disadvantages: Orchestrator becomes a single point of failure. Tight coupling between orchestrator and services. 2. Choreography Each service acts independently and reacts to events. How it works: The Flight Service publishes an event (FlightBooked) after successful booking. The Hotel Service listens to FlightBooked and books a hotel, then publishes HotelBooked. The Car Rental Service listens to HotelBooked and reserves a car. If a failure occurs, services handle compensations independently. Flow: User sends a booking request to the Flight Service. Flight Service publishes a FlightBooked event. Hotel Service subscribes to FlightBooked and publishes HotelBooked after success. Car Rental Service subscribes to HotelBooked and proceeds similarly. Advantages: Decentralized, no single point of failure. Loose coupling improves service independence. Disadvantages: Complex to manage compensating actions. Debugging and monitoring are harder. Saga Pattern Saga divides the transaction into a series of steps, each with a compensating action if it fails. In our example: Flight Service books a flight. If it fails, no action is needed (initial step). Hotel Service reserves a hotel. If it fails, it cancels the hotel reservation. Car Rental Service reserves a car. If it fails, it cancels the car reservation. If any service fails, previous steps execute compensating actions in reverse order. Advantages: Scales well with microservices. Better performance since each step commits locally. Disadvantages: Complex to design compensating actions. No strict consistency; eventual consistency is guaranteed. The saga pattern could be implemented as a Choreographed as well as Orchestrated process but mostly its always Choreographed. Two Phase Commit 2PC is a protocol to ensure strict consistency across distributed services. In our example: Phase 1: Prepare Flight, Hotel, and Car Rental services prepare resources and lock them. They notify the coordinator (a central transaction manager) of readiness. Phase 2: Commit or Rollback If all services are ready, the coordinator sends a ‚Äúcommit‚Äù command. If any service fails, the coordinator sends a ‚Äúrollback‚Äù command. Advantages: Ensures strict consistency. Ideal for transactional systems requiring ACID compliance. Disadvantages: Poor scalability, locks may reduce performance. Single point of failure if the coordinator crashes. the 2PC is always Orchestrated Comparison Feature Saga Two-Phase Commit (2PC) Consistency Eventual consistency Strict consistency Performance High Low (due to locking) Failure Handling Compensating actions Rollback entire transaction Complexity High (due to compensations) Medium Scalability Scales well Limited scalability Best Use Case Microservices, high scale ACID transactions ","date":"2024-12-26","objectID":"/microservices-architecture-deep-dive-part-six-distributed-transactions/:5:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Six: Distributed Transactions","uri":"/microservices-architecture-deep-dive-part-six-distributed-transactions/"},{"categories":["microservices"],"content":"In this blog post I discuss what service mesh is, what problem does it solve and what are best known service mesh products are","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":" Table Of Contents ¬†Part 1 - Microservices Architecture Deep Dive ¬†Part 2 - API Gateways and Backend For Frontend Pattern ¬†Part 3 - Microservices Communication ¬†Part 4 - Service Discovery ¬†Part 5 - Service Mesh ¬†you are here ¬†Part 5 - Distributed Transactions ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"The Problem Imagine you are working with a microservices architecture and you have 10s of services running, And these services work together by communicating with each other to achieve a goal. Now imagine every team working on different microservices built using different tech stack need to write the inter service communication logic by hand. Thats a waste of time and effort. Isn‚Äôt it?. Because not only you have to call the services apis but you also need to handle things like retry logic, load balancing, api sercurity,service discovery, rate limiting, authentication, observeability and much more. Writing all this logic for every service in the system is cumbersome and error prone. Because now alot of time is going in to writing the communication middleware for the service and not the actual logic of the service. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:1:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"The Solution Service meshes present a very good solution to this problem, service mesh is a peice of software that abstracts away all the communication logic from the application layer and takes it to the network, now the application doesn‚Äôt need to worry about the communication detail and only need to focus on the service logic itself. a service mesh is a dedicated infrastructure layer for facilitating service-to-service communications between services or microservices using a proxy. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:2:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"API Gateway Vs Service Mesh API gateways and service meshes are two different architectural components that address different concerns in a microservices-based application. While they may have some overlapping functionality, they serve distinct purposes and are often used together for a comprehensive solution. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:3:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"API Gateway: Edge component: An API gateway is an entry point for external clients (such as web browsers, mobile apps, or other services) to access the microservices in the application. It acts as a reverse proxy and a single point of entry for all incoming requests, abstracting the underlying microservices from the clients. Request routing: It routes requests from clients to the appropriate microservices, based on the API path and other criteria. Authentication and authorization: API gateways often handle authentication and authorization for incoming requests, ensuring that only authorized clients can access the microservices. Rate limiting and throttling: It can enforce rate limiting and throttling policies on incoming requests to protect the application from being overwhelmed by excessive traffic. API transformation and aggregation: An API gateway can modify or transform requests and responses, as well as aggregate data from multiple microservices to provide a cohesive response to the client. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:3:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Service mesh: Internal communication: A service mesh is primarily focused on managing, controlling, and observing communication between microservices within the distributed system, rather than external client requests. Sidecar proxies: A service mesh uses lightweight network proxies (sidecars) deployed alongside each microservice, which handle inter-service traffic, enabling features like load balancing, traffic routing, and security enforcement. Resilience and fault tolerance: It provides resiliency features like circuit breaking, retries, and timeouts to enhance the fault tolerance of the microservices communication. Observability: A service mesh offers built-in observability for metrics, logs, and tracing, which enables in-depth monitoring and troubleshooting of microservices interactions. Security: It can enforce security policies such as mutual TLS, ensuring secure and encrypted communication between microservices. In summary, an API gateway is focused on managing external client access to microservices, whereas a service mesh manages communication between microservices within the distributed system. Both components can complement each other, with the API gateway serving as the ingress point for external requests and the service mesh ensuring reliable and secure communication within the application. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:3:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Key Concepts: Service mesh architecture is designed to provide a dedicated infrastructure layer for managing, controlling, and observing communication between microservices in a distributed system. Key components and concepts of service mesh architecture include: Data Plane The data plane is responsible for managing the traffic between microservices. It consists of lightweight network proxies, called sidecars, that are deployed alongside each microservice instance. Sidecars intercept and manage inter-service communication, handling tasks such as load balancing, traffic routing, and enforcing security policies. Control Plane The control plane is the central management layer of the service mesh, responsible for configuring and monitoring the data plane. It provides an interface for users to define and enforce policies, configurations, and traffic rules. The control plane also collects metrics, logs, and tracing information from the sidecars to provide observability into the microservices‚Äô communication. Sidecar Proxy A sidecar proxy is a lightweight network proxy deployed alongside each microservice instance, which intercepts and manages the traffic between microservices. Sidecar proxies are typically implemented using technologies like Envoy or Linkerd. They are responsible for load balancing, traffic routing, circuit breaking, retries, timeouts, and enforcing security policies such as mutual TLS. Traffic Management A service mesh enables fine-grained traffic management, allowing users to control and manipulate the flow of traffic between microservices. This includes features such as request routing based on criteria like headers, weights, or versions, load balancing algorithms, fault injection for testing purposes, and traffic shifting for canary deployments or blue-green rollouts. Observability A service mesh provides built-in observability for the entire microservices ecosystem. It typically includes collecting metrics for performance and resource usage, distributed tracing for end-to-end visibility of request flows, and log aggregation for troubleshooting and analysis. This information can be consumed by monitoring and visualization tools, helping users understand the behavior and health of their microservices. Security A service mesh can enhance the security of microservices communication by providing features like mutual TLS for encrypting traffic and ensuring the identity of communicating services. Additionally, it can enforce fine-grained access control policies based on various criteria such as service identity, request attributes, or metadata. Resiliency The service mesh architecture helps increase the overall resiliency of microservices-based applications by providing features like circuit breaking, retries, and timeouts, which mitigate the impact of failures, delays, and network issues. These features help improve the fault tolerance of the system and ensure the availability of critical services. In a service mesh architecture, the data plane and control plane work together to provide a comprehensive solution for managing, controlling, and observing microservices communication, allowing developers to focus on their application‚Äôs business logic while the service mesh handles the complexities of inter-service communication. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:4:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Advantages Of Service Mesh Advanced Traffic Management Enables fine-grained control over traffic routing, including canary deployments, blue-green deployments, and traffic splitting based on specific conditions. Service Discovery and Load Balancing Automatically discovers services and ensures optimal load balancing between instances. Observability Provides deep insights into system behavior through distributed tracing, metrics, and logging without modifying application code. Enhanced Security Facilitates mutual TLS (mTLS) encryption for service-to-service communication and enforces security policies at the network level. Fault Tolerance Includes built-in mechanisms such as retries, timeouts, circuit breakers, and rate limiting to improve resilience. Policy Enforcement Allows the implementation of custom policies for traffic control, authentication, authorization, and rate limiting. Decoupling Communication Logic Removes communication-related concerns (e.g., retries, encryption, and telemetry) from application code, simplifying the development process. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:5:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Disadvantages Of Service Mesh Increased Complexity Adds an additional layer to the architecture, requiring expertise to configure, deploy, and maintain effectively. Performance Overhead The sidecar proxies in a service mesh introduce latency and consume additional CPU and memory resources. Operational Overhead Requires setting up and maintaining the service mesh infrastructure, which may include upgrades, troubleshooting, and monitoring. Learning Curve Teams must invest time to understand service mesh concepts, tools, and configuration. Cost Implications More resources (compute, network, and storage) are needed to run the service mesh components, potentially increasing operational costs. Risk of Overengineering For small-scale systems or simple use cases, implementing a service mesh might be unnecessary and lead to overengineering. Compatibility Issues Integrating a service mesh with existing legacy systems or specific protocols might be challenging. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:6:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"The Patterns ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:7:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Sidecar Proxy Pattern This is the most popular and foundational pattern in service mesh architecture. A proxy (like Envoy) runs alongside each application instance in the same pod (in Kubernetes) or host. The proxy intercepts all inbound and outbound traffic, handling routing, observability, and security. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:7:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Service Mesh with eBPF This Uses EBPF (Extended Berkeley Packet Filter) in the Linux kernel to handle communication. Avoids traditional proxies by running network-related operations directly in the kernel. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:7:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Sidecar-Less Mesh Pattern Removes the need for individual sidecars by embedding proxy logic into the node or network infrastructure. The mesh logic can be integrated into the application runtime or centralized. ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:7:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Examples Of Service Mesh Software Likerd Consul Istio Cilium ","date":"2024-12-09","objectID":"/microservices-architecture-deep-dive-part-five-service-mesh/:8:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Five: Service Mesh","uri":"/microservices-architecture-deep-dive-part-five-service-mesh/"},{"categories":["microservices"],"content":"Service discovery is an essential process in any distributed microservices environment, as it makes the environment scalable and solves a very specific communication problem. In this blog post I will go deep into this process and what are the different patterns used to implement this.","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":" Table Of Contents ¬†Part 1 - Microservices Architecture Deep Dive ¬†Part 2 - API Gateways and Backend For Frontend Pattern ¬†Part 3 - Microservices Communication ¬†Part 4 - Service Discovery ¬†you are here ¬†Part 5 - Service Mesh ¬†Part 5 - Distributed Transactions ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"The Problem As i discussed in the last blog post, the communication patterns in microservices are way different than the patterns in monoliths, in monoliths the modules communicate using method calls but in case of microservices, services communicate using the network calls. This small difference has massive implications, now the services which are involved in communication are living potentially on different machines and to communicate over the network the services would need to know each others IP addresses. The naive solution is to hard code the IP addresses of every service the communicating service needs to communicate with in the code, but this is not prudent in case of highly distributed environments like microservices. But why? the reason is this that modern microservices are deployed in containers and they are also auto scaled, scaled up and down, both ways. As a result all these microservice instances running are highly ephemeral and tools like kubernetes are used to make sure all the services are up all the time. And the way it makes sure that the services are up and running is by running new instances of the service when it notices some instance go down or being problematic. Due to all this the IP addresses of the services are no more static and they keep on changing. And our solution of hard coding the servies IP addresses is rendered obsolete. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:1:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"The Solution: Service Registry The solution is service registry, we would have an additional service running at all times, which would act as a registry for all the services in the environment. Every new service which would be available in the environment would register to the service registry. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"The Process The service registry is running on the known IP. each service in the environment would register itself to the registry, for instance there is this new service called service A, on the startup this service is required to register to the service registry first, so that it is locateable by other services in the environment. Now if service B wants to talk to service A it would go to service registry and service registry would give service B the address of service A so that they can communicate with each other. you see now we would not face any problem if the IP addresses of the service container are dynamic and ephemeral, because whenever the service comes up it is required to register to service registry. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"Health Checks You may be wondering that how does the service registry know that some instance of the service has gone down and now past IP address is no more valid? for that service registry employs some method of service health check. Heart Beat Check some service registeries have a heart beat mechanism built in. service registry sends the periodic heart beats to registered services to know whether they are up or not, if they do not respond then the service IP is deemed invalid. Periodic Registration some service registeries require registered services to register again after a regular interval of time, if they fail to do so the IP address associated with the service which failed to register would be deemed invalid. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"The Types Of service Registry There are two main types of service registries, they differ in a way they go about the process of service discovery, the types are following client side service registery server side service registery Client Side Service Registry Consider the following example. You want to order pizza, you know the place you want to order from but you don‚Äôt know how to contact them, you go to google and search for the place and get their number, then you call them and order pizza. This is how the client side service registry works, in this example consider yourself service A the pizza place service B and google service registry. In client side registry you would ask the registry for the IP address and it will give you the IP address and then its you who contact the other service. Server Side Service Registry Consider the following example. You want to contact the CEO of some company, you don‚Äôt have the contact information of the CEO but you do know the exchange number of the company, you call the exchange and let them know you want to talk to CEO, they will not give you the CEO‚Äôs phone number but instead would forward your call to the CEO themselves. This is exactly how the server side registry would work, service A would contact the registry and tell it that it wants to contact the service B unlike the client side registry it will not give the IP of service B to you instead it will contact service B it self and act like a proxy. ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"Well Known Service Registries the following are well known service registries Consul Eureka ETCD Zookeeper ","date":"2024-12-05","objectID":"/microservices-architecture-deep-dive-part-four-service-discovery/:2:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Four: Service Discovery","uri":"/microservices-architecture-deep-dive-part-four-service-discovery/"},{"categories":["microservices"],"content":"In this blog post i discuss, How microservices communicate, and what are the common patterns followed, this post would be a primer, I will go deeper in to the different patterns in future posts","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":" Table Of Contents ¬†Part 1 - Microservices Architecture Deep Dive ¬†Part 2 - API Gateways and Backend For Frontend Pattern ¬†Part 3 - Microservices Communication ¬†you are here ¬†Part 4 - Service Discovery ¬†Part 5- Service Mesh ¬†Part 5 - Distributed Transactions ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"Preface In monoliths the application is divided into modules, those modules serve as logical separation, in microservices the application is divided into services which serve as physical separation, This changes things drastically, before the modules in monoliths used to communicate with each other using the method calls but in case of microservices the services would need to communicate using network calls. This presents different challenges and trade offs, we have to carefully manage these tradeoffs, there are different patterns which the industry leaders in microservices have comeup with which manage the tradeoffs really well in live environments. But still when deciding on the communication patterns for your microservices you have to pay painstaking attention to detail. Because you have to remember these communication patterns are playing with tradeoffs and you have to choose which fits best your design goals and business domain. ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:1:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"The mistake There is a mistake that engineers make very often when they are trying to move to a microservices architecture from a monolith application. They convert the application modules which were present in monolith to the services and then simply try to convert the inter module function calls in monolith to the RPC calls in microservices. This happens because the engineers have wrong assumptions about microservices (or distributed systems). They are still assuming somethings which they assumed for monolithic architecture like they have a reliable network (which is not true, networks are never reliable) and another assumption thy could be making is latency is still zero just like in monoliths, both assumptions are far from truth, and these false assumptions and many other fallacies are coverd in wikipedia entry Fallacies of distributed computing. If you translate all the inter module function calls to RPC calls, your services would be very chatty, which is the last thing we want. In a monolith, network was not being used to communicate unlike microservices, and every call now on the network has a latency which we want to reduce. ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:2:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"Challenges The common challenges in microservices communications include following Network Latency:Network calls are slower than internal function calls. Service Discovery: Services need mechanisms to locate one another dynamically. Fault Tolerance: Failures in communication can cause cascading issues. Data Consistency: Ensuring consistency across distributed services. Security: Protecting communication channels and data in transit. Protocol Complexity: Choosing between REST, gRPC, or message brokers. ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:3:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"Communication Types Client and services can communicate through many different types of communication, each one targeting a different scenario and goals. Initially, those types of communications can be classified in two axes. The first axis defines if the protocol is synchronous or asynchronous: HTTP is a synchronous protocol for communication. The client sends the request and waits for the response to continue. Even if the http requests are being pipelined 1, even then the responses will be in sequence and the client which sent the request has to wait to get the response and would only then continue doing some thing else, you can think of it as a blocking communication mechanism. Protocols like AMQP2 are asynchronous, In this type of communication the client sends the message/request and does not wait for the response from the reciever(s) to continue doing other things (you can think of this like email communication). The second axis defines if the communication has a single receiver or multiple receivers: Single receiver. Each request must be processed by exactly one receiver or service. An example of this communication is the Command pattern. Multiple receivers. Each request can be processed by zero to multiple receivers. This type of communication must be asynchronous. An example is the publish/subscribe mechanism used in patterns like Event-driven architecture. This is based on an event-bus interface or message broker when propagating data updates between multiple microservices through events; it‚Äôs usually implemented through a service bus or similar artifact. don‚Äôt get bogged down by the different concepts like pub/sub and event-driven architecture, i will go into the detail of how these things work in future posts. A microservice-based application will often use a combination of these communication styles. The most common type is single-receiver communication with a synchronous protocol like HTTP/HTTPS when invoking a regular Web API HTTP service. Microservices also typically use messaging protocols for asynchronous communication between microservices. These axes are good to know so you have clarity on the possible communication mechanisms, but they‚Äôre not the important concerns when building microservices. Neither the asynchronous nature of client thread execution nor the asynchronous nature of the selected protocol are the important points when integrating microservices. What is important is being able to integrate your microservices asynchronously while maintaining the independence of microservices. ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:4:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"Asynchronous Integration As mentioned, the important point when building a microservices-based application is the way you integrate your microservices. Ideally, you should try to minimize the communication between the internal microservices. The fewer communications between microservices, the better. But in many cases, you‚Äôll have to somehow integrate the microservices. When you need to do that, the critical rule here is that the communication between the microservices should be asynchronous. That doesn‚Äôt mean that you have to use a specific protocol (for example, asynchronous messaging versus synchronous HTTP). It just means that the communication between microservices should be done only by propagating data asynchronously, but try not to depend on other internal microservices as part of the initial service‚Äôs HTTP request/response operation. If possible, never depend on synchronous communication (request/response) between multiple microservices, not even for queries. The goal of each microservice is to be autonomous and available to the client consumer, even if the other services that are part of the end-to-end application are down or unhealthy. If you think you need to make a call from one microservice to other microservices (like performing an HTTP request for a data query) to be able to provide a response to a client application, you have an architecture that won‚Äôt be resilient when some microservices fail. Moreover, having HTTP dependencies between microservices, like when creating long request/response cycles with HTTP request chains, as shown in the first part of the diagram, not only makes your microservices not autonomous but also their performance is impacted as soon as one of the services in that chain isn‚Äôt performing well. The more you add synchronous dependencies between microservices, such as query requests, the worse the overall response time gets for the client apps. In summary if client requests something from microservice A and this service can‚Äôt fulfill the request on its own and it talks to microservice B and consequently B needs to talk to microservice C to fulfill the request, then it means that these services are not autonomous. And if the communication between all these services is synchronous , the latency would keep on adding with each request in the chain and if any single service fails in the chain the failure would cascade and the whole chain would fail. As shown in the above diagram, in synchronous communication a ‚Äúchain‚Äù of requests is created between microservices while serving the client request. This is an anti-pattern. In asynchronous communication microservices use asynchronous messages or http polling to communicate with other microservices, but the client request is served right away. If your microservice needs to raise an additional action in another microservice, if possible, do not perform that action synchronously and as part of the original microservice request and reply operation. Instead, do it asynchronously (using asynchronous messaging or integration events, queues, etc.). But, as much as possible, do not invoke the action synchronously as part of the original synchronous request and reply operation. And finally (and this is where most of the issues arise when building microservices), if your initial microservice needs data that‚Äôs originally owned by other microservices, do not rely on making synchronous requests for that data. Instead, replicate or propagate that data (only the attributes you need) into the initial service‚Äôs database by using eventual consistency. duplicating some data across several microservices isn‚Äôt an incorrect design or anti pattern ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:5:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"References pipelining¬†‚Ü©Ô∏é AMQP¬†‚Ü©Ô∏é ","date":"2024-12-04","objectID":"/microservices-architecture-deep-dive-part-three-communications/:6:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Three: Communications","uri":"/microservices-architecture-deep-dive-part-three-communications/"},{"categories":["microservices"],"content":"In this blog post i discuss the utility of API gateways, what problem they solve? and i will also discuss the importance of BFF pattern","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"API gateway is a common pattern majority of microservices out in the world follow, to address some issues and Backend for frontend is a pattern which is a natural extension of API gateway pattern which helps the microservices scale very smoothly. Table Of Contents ¬†Part 1 - Microservices Architecture Deep Dive ¬†Part 2 - API Gateways and Backend For Frontend Pattern ¬†you are here ¬†Part 3 - Microservices Communication ¬†Part 4 - Service Discovery ¬†Part 5 - Service Mesh ¬†Part 5 - Distributed Transactions ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"The Problem People who are new to learning about microservices architecture and when they first come across the API gateway pattern, naturally they would want to go a little deep into what gateways are, and when they do that they are often confused, because they get different uses and definitions of API gateway that they no longer could figure out what problem is it trying to solve. let me tell you API gateways exist to solve a very specific, single problem which is related to communication between the clients and services, everything else that you hear about API gateways being capable of doing are just some nice sideeffects we use to our advantage. Imagine yourself being a frontend engineer and you are creating the UI for the ecommerce application, you go to the backend engineer and ask him that you are developing the login experience what API endpoint should you use on the client side? and the backend engineer would tell you that the Authentication Service is the one which would handle the login, so they give you the endpoint for authentication service, now after some days you start developing the Cart functionality on the frontend and you get to know from the backend team that, you would need to make use of two more microservices the payment and shipping service to implement that and this continues for the life time of the project. Do you see the problem? The clients are directly communicating with the microservices, utilizing the API exposed by the services, and this is a problem, the client is highly coupled with the backend services, if some endpoint changes the client would need to change too. and coupling is bad as i discussed in my last post. We need an abstraction between the clients and the services, and that abstraction is API Gateway. The API gateways sits between the clients and services and now clients only need to know about the gateway and only talk to it, the clients don‚Äôt need to worry about hundreds of services to talk to, gateway will handle that. This also decouples the clients from services, because now microservices can change all they want to change and client won‚Äôt need changing because now there is a level of indirection between clients and services. ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"The Side-Effects This communication problem is the primary problem that gateways exist to solve, but now that we have single point of entry to the microservice architecture we have, we can accomplish alot of other good things for our infrastructure. Now that gateway is the entrypoint for our infra we can accomodate the cross cutting features in the gateway itself, because these features are required by all the services in the infra, obviously it would be a madness to implement these for each service individually in different techstacks. Following sections will go into some of the features API Gateways implement (the features which are commonly attributed to API gateways) Authentication This is the major and obvious one, every microservice needs some kind of authentication and identity management, so why do it separately for every service, so the common pattern is to have authentication placed in an Edge Service like API Gateway. Protocol Translation As i did discuss in the last post one of the advantage of having microservices is flexibility with choosing the technology for the implementation of the service, one microservice can have an REST api, one could have graphQL the other could have a grpc implemented. If clients want to talk to them, they have to speak all these languages (protocols) to implement the client side successfully which is madness. So API gateway solves this problem as well by sitting between the services and clients, it acts as a protocol interpreter because as services are only talking to the gateway they only need to speak one protocol mainly REST and API gateway would take care of talking to diverse services in diverse protocols. Rate Limiting Another cross cutting concern is rate limiting, API gateway can implement the cutting edge rate limiting algorithms on the edge instead of these algorithms being part of every service which saves us from redundancy. Request Routing and Load Balancing API gateway is also responsible to Route incoming API requests to appropriate backend services based on the request path, headers, or other criteria. API gateway is also used to implement the load balancer for the services to Distribute traffic across multiple service instances for high availability and load balancing. Caching API gateway is naturally a good candidate for caching the service responses to reduce latency. Monitoring And Logging API gateways being the entrypoint are very suitable for the implementation of monitoring and logging solutions. whenever the gateway comes into action simply log the stuff and trigger the monitoring middleware. Others Some other common functionalities of API gateways include Service discovery Security features CORS policies API versioning ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"How to scale Now i am sure one question must have popped in your mind, that wouldn‚Äôt the API gateway become a bottle neck as all the traffic is going through the gateway and it is acting like a funnel? you are right! there is a potential of gateway becoming a bottle neck, but there is a simple solution. We can horizontally scale the API gateway and then put a load balancer in front of it, now the clients request will come to load balancer first and then the load balancer will distribute the request among the gateways. ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"Backend For Frontend The Problem During the whole blog post i have been mentioning the word ‚ÄúClient‚Äù, but the client itself is a generic term and it could be many things like a client could be a PC, a mobile, an IOT device or another microservice. All these clients are different in many ways, a PC for instance has all the resources in abundance like big screen, alot of memory, big compute power e.t.c, mobiles on the other hand have small screen real estate, small memory, small compute and also limited power supply. This is the reason the backend APIs they are consuming have to be tailor made because all these clients have their own strengths and weaknesses and our goal as engineers is to exploit their strengths and mitigate the weaknesses as much as we can. The mobile clients and PC clients have different resources hence they can‚Äôt just have same API endpoints available to consume, mobile clients show limited data and try to make as few HTTP round trips to fetch data as possible because each http request drains battery and increases latency, technology like graphql is more suitable for mobiles then the HTTP REST api. Following is the depiction of difference between simple API Gateway and the gateways following the BFF architecture You see now all the clients have a tailored gateway now they will get what they need in the most efficient way possible. All the data fetching and then aggregation will now move to the tailored gateway and the client will focus on the frontend logic only. ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"Useful Links sam newman BFF amazon api gateway microsoft api gateway architecture ","date":"2024-12-03","objectID":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/:0:5","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive Part Two : API Gateways and Backend For Frontend Pattern","uri":"/microservices-architecture-deep-dive-part-two--api-gateways-and-bff-pattern/"},{"categories":["microservices"],"content":"This blog series is all about microservices, we will start with simple definition of microservices and and go all the way to know how to implement them effectively and when do they make sense and when is it a stupid idea to implement microservices","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices are one of the most popular methodology to develop and deploy the software systems. In popularity it is only second to Monoliths (or Modular Monoliths). This blog series is all about microservices, how do they differ from monoliths, what are their pros and cons, when do they make sense and how to implement microservices effectively. Table Of Contents ¬†Part 1 - Microservices Architecture Deep Dive ¬†you are here ¬†Part 2 - API Gateways and Backend For Frontend Pattern ¬†Part 3 - Microservices Communication ¬†Part 4 - Service Discovery ¬†Part 5 - Service Mesh ¬†Part 5 - Distributed Transactions ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:0:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: The Inception Microservices don‚Äôt have any precise inception date, but rather evolved over time. It gained prominence around 2011 largely due to shift towards cloud and distributed computing. following are the things which led to microservices ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Service Oriented Architecture (SOA1) Microservices evolved as a refinement of SOA, which focused on creating loosely coupled, reusable services , but SOA had some severe afflictions like heavy middleware and complexity to name a few. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Cloud Computing The growing adoption of cloud platforms like aws highlighted the need for smaller, more independent services (by the way it was companies like aws which pioneered the breaking down of monoliths into smaller services) ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Martin Fowler and James Lewis‚Äôs Definition In 2014 in their influential article, titled ‚ÄúMicroservices: A Definition of This New Architectural Term‚Äù, Fowler and Lewis codified the principles and patterns of microservices. This was pivotal in standardizing the concept and its terminology. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Early Adopters And Case Studies Companies like Netflix and Amazon implemented microservices early, demonstrating its effectiveness in scaling and adapting to dynamic workloads. Netflix‚Äôs architecture shift started in the late 2000s and became a famous case study for microservices. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:1:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: A Definition While there is no precise definition of this architectural style, there are certain common characteristics around organization around business capability, automated deployment, intelligence in the endpoints, and decentralized control of languages and data. This is how martin fowler describes microservices, and in my opinion he is on point. The goal of this blog post is to discuss these characteristcs that make up microservices that he is talking about. And in subsequent blog posts i will go deep in to the tools which the Engineers use to work with microservices effectively. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:2:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: The Characteristics ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Preface Microservices are independently releaseable services which are modeled around the business domain (e.g an ecommerce web application will have services like inventory, order management and shipping), each service exposes the API so that other services can use its functionality, but the implementation details remain hidden, once we have small services the more complex bigger system could be built using these small services like a lego. Information hidding2 is very important for microservices to work, every service hides as much information as possible from other services because that would make sure that in future if a microservice needs to change it can change without effecting the other services using this service which is subject to change. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Independent Deployability This refers to the characteristic of a service, in which you can change a service in some way and deploy it and the new feature or change is now available to the software‚Äôs users, you don‚Äôt need to change any other service, there are no cascading changes. some examples of changes would be , a small bug fix , api endpoint changes , addition of a whole new feature or a database schema change. Achieving this level of decoupling in a real world system is extremely difficult and engineers in the real world could relax this rule of microservices. nonetheless this is the most important characteristic of microservices, if you are able to achieve independent deployability for your application, you have already solved alot of problems which microservices promise to solve. And if you focus on this characteristic as the out come you would achieve numerous other benefits of microservices because independent deployability could only be achieved if you get alot of other things right. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Services Owning there Own State (aka every service having its own database) This characteristic was synonymous to microservices few years ago , it went without saying that microservices should have their own databases each, but for the past few years it has become a point of contention, and people tend to challenge this rule more and more, the reason for contention is this that this rule does solve alot of problems but also create many of its own as well, like Distributed Transactions, which are very hard to get right. This characteristic suggests that if service A needs some data from the database of some other microservice B, it should ask microservice B through its API to hand over the data and not share the database, this way the services will have control over what is visible to other services and what is not and access to data would be limited, and if the access to the data is limited by the API requests then service B can keep on changing e.g the schema of the database or even replace the whole database and jump from sql to no-sql database even than service A would not need to change because the API which service B is providing is the same. If we want our services to be independently deployable we need to promote backward compatibility and limit the backward incompatibility, Its that simple, but hard to achieve because you need to have a very vivid vision for the service you are designing, and you have to think in much advance what to expose and what not to expose to other services, If you make some change to a service A which is backward incompatible with the services consuming service A , all the consuming services are forced to change, so ‚Äúservices owning their own state‚Äù is aiming to promote backward compatibility. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"What About Size This is one of the most discussed topic in the microservices arena , what should be the size of a microservice? obviously there could be many answers to this question, one answer which i have heard is ‚Äúthis is something which should be subjective‚Äù, I don‚Äôt agree with this because if microservice‚Äôs size is being determined by a person‚Äôs (or multiple people‚Äôs) subjectivity then there would be hundreds of engineers and project managers who would work on the microservice during its life time, whose subjectivity should the team adhere to. there are other answers which do make sense like ‚Äúmicroservice should be as big as your head‚Äù which means that microservice should be big enough so that a person working on it can fit it in his/her head, they should have complete idea how the microservice works, what are its interfaces, how is it internally coupled, whats exists where e.t.c. This definition of size is also somewhat contentious, because every person‚Äôs ability to fit things in his or her head is different. this idea of a systems being as big as a persons head is not new, it was one of the goals of OOP as well, you design classes and encapsulate the functionality, exposing small interface of the class and giving class a name , now whenever the programmer needed to reason about the code in his head or in communication with someone else instead of mentioning the whole functionality and interface the person can alias it with the name of the class. interesting isn‚Äôt it? The Best definition of size would be, ‚ÄúA microservice should have as small of an interface as possible‚Äù, and this is very self-explanatory. And this aligns with information hiding aspect i have just mentioned. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Design For Failure One characteristic that martin fowler lists is designing the services for failure, but what does this mean? Well this means that at every point of a microservices design we should be assuming that the failure can happen and handle the failure accordingly. This is one of the side effects of breaking the monolith down into services, Because before the application was a single process monolith and now the monolith has become different services residing in different processes maybe on different computers and when they communicate failures could occur. Whole projects and methodologies have emerged because of this, projects like grpc is a RPC3 framework which handles all the boilerplate for fault and error handling for the services, so you don‚Äôt have to right the boilerplate and can focus on the logic of the service, and methodology like chaos testing has emerged to rigorously test the services in hostile circumstances. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:5","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Smart Endpoints And Dumb Pipes This characteristic suggests that, the communication channels between microservices should do the bare minimum which is communicate and thats it and all the other shenanigans should be left to the services which are communicating. This is a lesson we have learned from microservices predecessor ‚ÄúService Oriented Architecture‚Äù which used ESB (Enterprise Service Bus) for communications which was a fully loaded communication system, and this ESB is what lead to the demise of SOA REST is prime example of this, it is a very dumb protocol, service A sends request to service B, service B gets the response ready and sends back the response, plain and simple, REST does not introduce any kind of magic, it prefers being dumb and just gives us simple rules to abide by. The messaging queues are another good example which contribute to the service communication without being too smart, they are simple queue datastructure implementation which come with certain guarantees and aid services with async communication. I will go deep into messaging queues in the future blog post about sync and async communication. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:3:6","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: Monolith To Microservice Decomposition Patterns It is not possible to break the monolith down into Microservices in a day, its a complex process which takes alot of thinking and planning on engineers part, but as the time has went by and more and more big companies like netflix , uber and aws have adopted microservices, they have comeup with patterns of decomposition which are now battle tested and work really well, so engineers need to know those patterns so they don‚Äôt reinvent the wheel, following i will list down some patterns and i will discuss some of them in the future blog posts. strangler fig pattern domain driven design Event driven decomposition database splitting backend for frontend ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:4:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: Advantages ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Flexibility With Technology Choice This is one of the best pro of having microservices architecture, you can choose to develop every service with different tech stack, for instance you can use a database for a service which is suitable for the service workload and now you are noot shackled by the monolith, e.g if the workloads for the service are write heavy, you can use a DBMS which uses LSM tree as an internal datastructure but if the workload is read heavy you can use B-Tree based DBMS, same story repeats for the columnar or row based databases. In the same way you can choose the implementation language for the service on different criterias, Golang if you want good out of the box concurrency and python if good library support is needed and concurrency is not much of a concern. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Robustness Microservices are more robust compared to monoliths, if monolith application fails the system fails, in case of microservices a single service could fail for some time but the whole system does not come down crumbling, if the failure is not cascading. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Scaling Just like microservices are invidually deployable, they are also individually scaleable, and thats a big deal, in case of monoliths you need to scale the whole application even if small part of the application needed scaling Imagine an e-commerce platform with the following functionalities: User Service: Handles user authentication and profile management. Order Service: Manages order placement and history. Inventory Service: Tracks product stock. Recommendation Service: Provides personalized product recommendations. In a monolithic architecture, all these services are part of a single application. If product recommendations experience a spike in demand (e.g., during a sale), the entire monolith must scale, even though only the Recommendation Service requires more resources. In a microservices architecture, these functionalities are separate services. Each can be independently scaled based on demand: During a sale: Recommendation Service: Scales to handle the increased load, spinning up additional instances. User Service, Order Service, and Inventory Service: Remain unaffected and do not incur extra costs. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Ease Of Deployment Imagine changin one line in million line monolith application and redeploying, thats too much risk and apart from that you would also need to run all the tests hoping that the change has broken nothing. Now on the other hand microservices are small code bases and changes and deployments both are fast and even if anything breaks its easy to trace and fix. you can comeup with alot more advantages of microservices but these are the main advantages which entice mojority engineering teams to invest time and effort to migrate to microservices architecture ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:5:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Microservices: Disadvantages ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Developer Experience One of the main pain points of developing a microservices architecture is terrible developer experience, because it is very difficult to mimic the runtime environment locally, your single computer can only run fraction of total microservices. and if you are developing in the cloud thats even worse because the feedback cycles are longer. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:1","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Technology Overload There are like 50 solutions for the same problem in the market and every engineering team is using different tools to solve the same problem in different companies,so the engineers have to keep up with the tool evolution ever so often, which is very demanding for example there are 20 tools to create a service mesh which i can name off the cuff right now, but all of them are doing the same thing (there internal implementation details could differ). secondly the advantage of flexibility with the technology could turn into a disadvantage quickly, because you have so many technology choices to solve a problem that you can suffer with choice paralysis and that could consequently postpone the decisions. and lastly you can gradually keep on adding new tools to the project like you start with docker swarm and then gradually shift to kubernetes and the same way you keep on adding tools, and when there is new onboarding on the team the new person would be terrified watching so many unnecessary tech being used, and that could effect the team productivity. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:2","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Monitoring And Debugging In monoliths there is single application running on the single server and that makes it very easy to monitor it and debugging the problems, because the life of a query is so simple, the client makes a request and the single server responds to the request, that is it. But in case of microservices the life of the query gets exponentially bigger with the number of microservices communicating to full fill the query. consequently if there is some problem in the system its very difficult to pin point where the problem really is, and it is also very hard to monitor the whole system and get a holistic view of things, below the image is depicting a problem in microservices called Big ball of mud, it refers to the communication between different microservices as big ball of mud, and it sure is ball of mud, now you can imagine why it is so hard to monitor and debug microservices ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:3","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Security With a single-process monolithic system, much of our information flowed within that process. Now, more information flows over networks between our services. This can make our data more vulnerable to being observed in transit and also to poten‚Äê tially being manipulated as part of man-in-the-middle attacks. This means that you might need to direct more care to protecting data in transit and to ensuring that your microservice endpoints are protected so that only authorized parties are able to make use of them. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:4","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Latency With a microservice architecture, processing that might previously have been done locally on one processor can now end up being split across multiple separate micro‚Äê services. Information that previously flowed within only a single process now needs to be serialized, transmitted, and deserialized over networks that you might be exer‚Äê cising more than ever before. All of this can result in worsening latency of your system. ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:5","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Data Consistency Shifting from a monolithic system, in which data is stored and managed in a single database, to a much more distributed system, in which multiple processes manage state in different databases, causes potential challenges with respect to consistency of data. Whereas in the past you might have relied on database transactions to manage state changes, you‚Äôll need to understand that similar safety cannot easily be provided in a distributed system. The use of distributed transactions in most cases proves to be highly problematic in coordinating state changes ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:6:6","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Useful Links Microservices at netflix DoorDash scaling microservices Snap chat‚Äôs journey from monolith to microservices ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:7:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"Book Recommendation Read the brilliant book by Sam Newman called building microservices4 ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:8:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"},{"categories":["microservices"],"content":"References what is service oriented architecture¬†‚Ü©Ô∏é information distribution aspects of design methodology¬†‚Ü©Ô∏é Remote procedure calls¬†‚Ü©Ô∏é Brilliant book: building microservices¬†‚Ü©Ô∏é ","date":"2024-11-29","objectID":"/microservices-architecture-deep-dive-part-one/:9:0","tags":["microservices","distributed systems"],"title":"Microservices Architecture Deep Dive: Part One","uri":"/microservices-architecture-deep-dive-part-one/"}]